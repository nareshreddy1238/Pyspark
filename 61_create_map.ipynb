{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99201a40-a2d2-45ff-a3aa-84fa0921a028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n",
      "+-----+---------+------+--------+\n",
      "|id   |dept     |salary|location|\n",
      "+-----+---------+------+--------+\n",
      "|36636|Finance  |3000  |USA     |\n",
      "|40288|Finance  |5000  |IND     |\n",
      "|42114|Sales    |3900  |USA     |\n",
      "|39192|Marketing|2500  |CAN     |\n",
      "|34534|Sales    |6500  |USA     |\n",
      "+-----+---------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName('com').getOrCreate()\n",
    "data = [ (\"36636\",\"Finance\",3000,\"USA\"), \n",
    "    (\"40288\",\"Finance\",5000,\"IND\"), \n",
    "    (\"42114\",\"Sales\",3900,\"USA\"), \n",
    "    (\"39192\",\"Marketing\",2500,\"CAN\"), \n",
    "    (\"34534\",\"Sales\",6500,\"USA\") ]\n",
    "schema = StructType([\n",
    "     StructField('id', StringType(), True),\n",
    "     StructField('dept', StringType(), True),\n",
    "     StructField('salary', IntegerType(), True),\n",
    "     StructField('location', StringType(), True)\n",
    "     ])\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a27856-e7db-4858-a11e-d9f344dddd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- propertiesMap: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+-----+---------+---------------------------------+\n",
      "|id   |dept     |propertiesMap                    |\n",
      "+-----+---------+---------------------------------+\n",
      "|36636|Finance  |{salary -> 3000, location -> USA}|\n",
      "|40288|Finance  |{salary -> 5000, location -> IND}|\n",
      "|42114|Sales    |{salary -> 3900, location -> USA}|\n",
      "|39192|Marketing|{salary -> 2500, location -> CAN}|\n",
      "|34534|Sales    |{salary -> 6500, location -> USA}|\n",
      "+-----+---------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,lit,create_map\n",
    "df = df.withColumn(\"propertiesMap\",create_map(lit(\"salary\"),col(\"salary\"),lit(\"location\"),col(\"location\"))).drop(\"salary\",\"location\")\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10856d81-d16d-4d5e-b0c7-e373be5df68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------------------+\n",
      "|   id|     dept|map_keys(propertiesMap)|\n",
      "+-----+---------+-----------------------+\n",
      "|36636|  Finance|     [salary, location]|\n",
      "|40288|  Finance|     [salary, location]|\n",
      "|42114|    Sales|     [salary, location]|\n",
      "|39192|Marketing|     [salary, location]|\n",
      "|34534|    Sales|     [salary, location]|\n",
      "+-----+---------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_keys\n",
    "df.select(df.id,df.dept, map_keys(df.propertiesMap)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3fd4dd-3f5f-4c0e-af08-92e1b3c31f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------------------------+\n",
      "|   id|     dept|map_values(propertiesMap)|\n",
      "+-----+---------+-------------------------+\n",
      "|36636|  Finance|              [3000, USA]|\n",
      "|40288|  Finance|              [5000, IND]|\n",
      "|42114|    Sales|              [3900, USA]|\n",
      "|39192|Marketing|              [2500, CAN]|\n",
      "|34534|    Sales|              [6500, USA]|\n",
      "+-----+---------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_values\n",
    "df.select(df.id,df.dept, map_values(df.propertiesMap)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722a7b9-0faa-44f8-a131-fc75d125e6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
