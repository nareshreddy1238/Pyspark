{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae417305",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "840b06e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "| Naresh| 25|\n",
      "|MichalC| 26|\n",
      "|  Virat| 45|\n",
      "|   Demo| 67|\n",
      "|     Hi| 89|\n",
      "+-------+---+\n",
      "\n",
      "+--------+---+------+\n",
      "|    Name|Age|Gender|\n",
      "+--------+---+------+\n",
      "|  Naresh| 25|     M|\n",
      "|  Michal| 27|     F|\n",
      "|   Virat| 29|     M|\n",
      "|    Demo| 30|     F|\n",
      "|      Hi| 40|     M|\n",
      "|    Jump| 51|     F|\n",
      "|    Mabu| 39|     M|\n",
      "|Shaheena| 30|     F|\n",
      "| Madhena| 40|     F|\n",
      "+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('demo').getOrCreate()\n",
    "df1 = spark.read.option(\"delimiter\",\",\").csv(\"input1.csv\",header=True)\n",
    "df1.show()\n",
    "df2 = spark.read.option(\"delimiter\",\",\").csv(\"input2.csv\",header=True)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846f2f3",
   "metadata": {},
   "source": [
    "# Method 1: withColumn & lit & union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a59d804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+\n",
      "|   Name|Age|Gender|\n",
      "+-------+---+------+\n",
      "| Naresh| 25|  null|\n",
      "|MichalC| 26|  null|\n",
      "|  Virat| 45|  null|\n",
      "|   Demo| 67|  null|\n",
      "|     Hi| 89|  null|\n",
      "+-------+---+------+\n",
      "\n",
      "+--------+---+------+\n",
      "|    Name|Age|Gender|\n",
      "+--------+---+------+\n",
      "|  Naresh| 25|  null|\n",
      "| MichalC| 26|  null|\n",
      "|   Virat| 45|  null|\n",
      "|    Demo| 67|  null|\n",
      "|      Hi| 89|  null|\n",
      "|  Naresh| 25|     M|\n",
      "|  Michal| 27|     F|\n",
      "|   Virat| 29|     M|\n",
      "|    Demo| 30|     F|\n",
      "|      Hi| 40|     M|\n",
      "|    Jump| 51|     F|\n",
      "|    Mabu| 39|     M|\n",
      "|Shaheena| 30|     F|\n",
      "| Madhena| 40|     F|\n",
      "+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df1.union(df2) #error union can perform same number of columns\n",
    "from pyspark.sql.functions import lit\n",
    "df_add = df1.withColumn(\"Gender\",lit(\"null\"))\n",
    "df_add.show()\n",
    "df_add.union(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47ea82",
   "metadata": {},
   "source": [
    "#  Method 2: Schema & Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e7740eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType (\n",
    "        [\n",
    "            StructField(\"Name\",StringType(),True),\n",
    "            StructField(\"Age\",StringType(),True),\n",
    "            StructField(\"Gender\",StringType(),True)\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3294b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.option(\"delimiter\",\",\").csv(\"input1.csv\",header=True,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32a86125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 =  spark.read.option(\"delimiter\",\",\").csv(\"input2.csv\",header=True,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d57a39bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n",
      "|    Name|Age|Gender|\n",
      "+--------+---+------+\n",
      "|  Naresh| 25|  null|\n",
      "| MichalC| 26|  null|\n",
      "|   Virat| 45|  null|\n",
      "|    Demo| 67|  null|\n",
      "|      Hi| 89|  null|\n",
      "|  Naresh| 25|     M|\n",
      "|  Michal| 27|     F|\n",
      "|   Virat| 29|     M|\n",
      "|    Demo| 30|     F|\n",
      "|      Hi| 40|     M|\n",
      "|    Jump| 51|     F|\n",
      "|    Mabu| 39|     M|\n",
      "|Shaheena| 30|     F|\n",
      "| Madhena| 40|     F|\n",
      "+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.union(df4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b7a22",
   "metadata": {},
   "source": [
    "# Method 3: Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "792ac0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.read.option(\"delimiter\",\",\").csv(\"input1.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11f91ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 =  spark.read.option(\"delimiter\",\",\").csv(\"input2.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db7076c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n",
      "|    Name|Age|Gender|\n",
      "+--------+---+------+\n",
      "|    Demo| 30|     F|\n",
      "|    Demo| 67|  null|\n",
      "|      Hi| 40|     M|\n",
      "|      Hi| 89|  null|\n",
      "|    Jump| 51|     F|\n",
      "|    Mabu| 39|     M|\n",
      "| Madhena| 40|     F|\n",
      "|  Michal| 27|     F|\n",
      "| MichalC| 26|  null|\n",
      "|  Naresh| 25|     M|\n",
      "|Shaheena| 30|     F|\n",
      "|   Virat| 29|     M|\n",
      "|   Virat| 45|  null|\n",
      "+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7= df5.join(df6,on=[\"Name\", \"Age\"],how=\"Outer\")\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4ce8d",
   "metadata": {},
   "source": [
    "# 4. Automated Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b33a3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = spark.read.option(\"delimiter\",\",\").csv(\"input1.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94046b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 =  spark.read.option(\"delimiter\",\",\").csv(\"input2.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3cb532bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(set(df8.columns)-set(df9.columns))\n",
    "list2 = list(set(df9.columns)-set(df8.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95ca7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n",
      "|    Name|Age|Gender|\n",
      "+--------+---+------+\n",
      "|  Naresh| 25|  null|\n",
      "| MichalC| 26|  null|\n",
      "|   Virat| 45|  null|\n",
      "|    Demo| 67|  null|\n",
      "|      Hi| 89|  null|\n",
      "|  Naresh| 25|     M|\n",
      "|  Michal| 27|     F|\n",
      "|   Virat| 29|     M|\n",
      "|    Demo| 30|     F|\n",
      "|      Hi| 40|     M|\n",
      "|    Jump| 51|     F|\n",
      "|    Mabu| 39|     M|\n",
      "|Shaheena| 30|     F|\n",
      "| Madhena| 40|     F|\n",
      "+--------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list1:\n",
    "    df9= df9.withColumn(i,lit(\"null\"))\n",
    "    \n",
    "for j in list2:\n",
    "    df8= df8.withColumn(j,lit(\"null\"))\n",
    "\n",
    "df8.union(df9).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fd8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
