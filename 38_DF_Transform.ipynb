{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90901c0-6903-4220-9f5c-8e26808e6a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CourseName: string (nullable = true)\n",
      " |-- fee: long (nullable = true)\n",
      " |-- discount: long (nullable = true)\n",
      "\n",
      "+----------+----+--------+\n",
      "|CourseName|fee |discount|\n",
      "+----------+----+--------+\n",
      "|Java      |4000|5       |\n",
      "|Python    |4600|10      |\n",
      "|Scala     |4100|15      |\n",
      "|Scala     |4500|15      |\n",
      "|PHP       |3000|20      |\n",
      "+----------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('com').getOrCreate()\n",
    "\n",
    "simpleData = ((\"Java\",4000,5), \\\n",
    "    (\"Python\", 4600,10),  \\\n",
    "    (\"Scala\", 4100,15),   \\\n",
    "    (\"Scala\", 4500,15),   \\\n",
    "    (\"PHP\", 3000,20),  \\\n",
    "  )\n",
    "columns= [\"CourseName\", \"fee\", \"discount\"]\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a22a099-680d-4ecb-9b18-4ee77d75688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|  ALICE| 25|\n",
      "|    BOB| 30|\n",
      "|CHARLIE| 22|\n",
      "+-------+---+\n",
      "\n",
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|  Alice| 50|\n",
      "|    Bob| 60|\n",
      "|Charlie| 44|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 22)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Example 1: Transform \"Name\" column to uppercase\n",
    "def to_upper_case(df):\n",
    "    return df.withColumn(\"Name\", upper(col(\"Name\")))\n",
    "\n",
    "# Example 2: Double the \"Age\" value\n",
    "def double_age(df):\n",
    "    return df.withColumn(\"Age\", col(\"Age\") * 2)\n",
    "\n",
    "df1= df.transform(to_upper_case)\n",
    "df1.show()\n",
    "df2 = df.transform(double_age)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31e4130c-4adf-4bc9-9a34-fca1f69052ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Lan1: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Lan2: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+----------------+------------------+---------------+\n",
      "|            Name|              Lan1|           Lan2|\n",
      "+----------------+------------------+---------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|\n",
      "+----------------+------------------+---------------+\n",
      "\n",
      "+------------------+\n",
      "|              lan1|\n",
      "+------------------+\n",
      "|[JAVA, SCALA, C++]|\n",
      "|[SPARK, JAVA, C++]|\n",
      "|      [CSHARP, VB]|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]),\n",
    " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]),\n",
    " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"])\n",
    "]\n",
    "df=spark.createDataFrame(data=data,schema=[\"Name\",\"Lan1\",\"Lan2\"])\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "# using transform() function\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import transform\n",
    "df.select(transform(\"Lan1\", lambda x: upper(x)).alias(\"lan1\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc41b1-f1fd-49c1-9337-509ee490336b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
