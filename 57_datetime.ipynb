{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b1f811-2ce4-4782-bd17-828707ca347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_timestamp: string (nullable = true)\n",
      "\n",
      "+---+-----------------------+-------------------+\n",
      "|id |input_timestamp        |timestamp          |\n",
      "+---+-----------------------+-------------------+\n",
      "|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n",
      "+---+-----------------------+-------------------+\n",
      "\n",
      "+---+-----------------------+-------------------+\n",
      "|id |input_timestamp        |timestamp_string   |\n",
      "+---+-----------------------+-------------------+\n",
      "|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n",
      "+---+-----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"Examples.com\").getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df=spark.createDataFrame(\n",
    "        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n",
    "        schema=[\"id\",\"input_timestamp\"])\n",
    "df.printSchema()\n",
    "\n",
    "#Timestamp String to DateType\n",
    "df.withColumn(\"timestamp\",to_timestamp(\"input_timestamp\")).show(truncate=False)\n",
    "# Using Cast to convert TimestampType to DateType\n",
    "df.withColumn('timestamp_string',to_timestamp('input_timestamp').cast('string')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7dfe3e-8dd4-46ca-ab9b-975e08deafa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               time|\n",
      "+-------------------+\n",
      "|2019-06-24 12:01:19|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(to_timestamp(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS').alias('time')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d48ec8c-25b0-4670-82ea-90670bb4f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2019-06-24 12:01:19|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2019-06-24 12:01:19|\n",
      "+-------------------+\n",
      "\n",
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2019-06-24 12:01:19|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select to_timestamp('2019-06-24 12:01:19.000') as timestamp\").show()\n",
    "#SQL CAST timestamp string to TimestampType\n",
    "spark.sql(\"select timestamp('2019-06-24 12:01:19.000') as timestamp\").show()\n",
    "#SQL Custom string to TimestampType\n",
    "spark.sql(\"select to_timestamp('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as timestamp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3a4579-6a62-4cf5-adfc-f73966d3706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(\n",
    "        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n",
    "        schema=[\"id\",\"input_timestamp\"])\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb2991c-33bd-46ae-815e-08837df8a18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+----------+\n",
      "|id |input_timestamp        |date_type |\n",
      "+---+-----------------------+----------+\n",
      "|1  |2019-06-24 12:01:19.000|2019-06-24|\n",
      "+---+-----------------------+----------+\n",
      "\n",
      "+---+-----------------------+----------+\n",
      "|id |input_timestamp        |date_type |\n",
      "+---+-----------------------+----------+\n",
      "|1  |2019-06-24 12:01:19.000|2023-09-19|\n",
      "+---+-----------------------+----------+\n",
      "\n",
      "+----------+\n",
      "|      time|\n",
      "+----------+\n",
      "|2019-06-24|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Timestamp String to DateType\n",
    "df.withColumn(\"date_type\",to_date(\"input_timestamp\")).show(truncate=False)\n",
    "\n",
    "#Timestamp Type to DateType\n",
    "df.withColumn(\"date_type\",to_date(current_timestamp())).show(truncate=False)\n",
    "\n",
    "df.select(to_date(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS').alias('time')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802276d2-e655-4332-a6de-90aacfb729c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+-------------------+----------+\n",
      "|id |input_timestamp        |ts                 |datetype  |\n",
      "+---+-----------------------+-------------------+----------+\n",
      "|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|2019-06-24|\n",
      "+---+-----------------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"ts\",to_timestamp(col(\"input_timestamp\"))).withColumn(\"datetype\",to_date(col(\"ts\"))) \\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bffc66bc-887d-4525-a17b-8b7581096e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+----------+\n",
      "|id |input_timestamp        |date_type |\n",
      "+---+-----------------------+----------+\n",
      "|1  |2019-06-24 12:01:19.000|2019-06-24|\n",
      "+---+-----------------------+----------+\n",
      "\n",
      "+---+-----------------------+----------+\n",
      "|id |input_timestamp        |date_type |\n",
      "+---+-----------------------+----------+\n",
      "|1  |2019-06-24 12:01:19.000|2019-06-24|\n",
      "+---+-----------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('date_type', col('input_timestamp').cast('date')).show(truncate=False)\n",
    "df.withColumn('date_type',to_timestamp('input_timestamp').cast('date')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f34d5c0a-2587-415b-b14a-faed302ef48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------+------------+--------------------+\n",
      "|current_date|yyyy MM dd|      MM/dd/yyyy|yyyy MMMM dd|      yyyy MMMM dd E|\n",
      "+------------+----------+----------------+------------+--------------------+\n",
      "|  2023-09-19|2023 09 19|09/19/2023 04:15| 2023 Sep 19|2023 September 19...|\n",
      "+------------+----------+----------------+------------+--------------------+\n",
      "\n",
      "+------------+----------+----------------+------------+--------------------+\n",
      "|current_date|yyyy_MM_dd|      MM_dd_yyyy|yyyy_MMMM_dd|      yyyy_MMMM_dd_E|\n",
      "+------------+----------+----------------+------------+--------------------+\n",
      "|  2023-09-19|2023 09 19|09/19/2023 04:15| 2023 Sep 19|2023 September 19...|\n",
      "+------------+----------+----------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('com').getOrCreate()\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df=spark.createDataFrame([[\"1\"]],[\"id\"])\n",
    "df.select(current_date().alias(\"current_date\"),\n",
    "          date_format(current_date(),\"yyyy MM dd\").alias(\"yyyy MM dd\"),\n",
    "          date_format(current_timestamp(),\"MM/dd/yyyy hh:mm\").alias(\"MM/dd/yyyy\"),\n",
    "          date_format(current_timestamp(),\"yyyy MMM dd\").alias(\"yyyy MMMM dd\"),\n",
    "          date_format(current_timestamp(),\"yyyy MMMM dd E\").alias(\"yyyy MMMM dd E\")).show()\n",
    "\n",
    "#SQL\n",
    "spark.sql(\"select current_date() as current_date, \"+\n",
    "      \"date_format(current_timestamp(),'yyyy MM dd') as yyyy_MM_dd, \"+\n",
    "      \"date_format(current_timestamp(),'MM/dd/yyyy hh:mm') as MM_dd_yyyy, \"+\n",
    "      \"date_format(current_timestamp(),'yyyy MMM dd') as yyyy_MMMM_dd, \"+\n",
    "      \"date_format(current_timestamp(),'yyyy MMMM dd E') as yyyy_MMMM_dd_E\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc9ff645-2436-4f57-8bfd-d1319ef60841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+\n",
      "|      date|current_date|datediff|\n",
      "+----------+------------+--------+\n",
      "|2019-07-01|  2023-09-19|    1541|\n",
      "|2019-06-24|  2023-09-19|    1548|\n",
      "|2019-08-24|  2023-09-19|    1487|\n",
      "+----------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datediff\n",
    "from pyspark.sql.functions import *\n",
    "data = [(\"1\",\"2019-07-01\"),(\"2\",\"2019-06-24\"),(\"3\",\"2019-08-24\")]\n",
    "df=spark.createDataFrame(data=data,schema=[\"id\",\"date\"])\n",
    "\n",
    "df.select(col(\"date\"),current_date().alias(\"current_date\"),\n",
    "      datediff(current_date(),col(\"date\")).alias(\"datediff\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1751856-ca8c-4d92-b35c-594451e42eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-----------+---------------+-----------------+---------------+\n",
      "| id|      date|datesDiff|  montsDiff|montsDiff_round|        yearsDiff|yearsDiff_round|\n",
      "+---+----------+---------+-----------+---------------+-----------------+---------------+\n",
      "|  1|2019-07-01|     1541|50.58064516|          50.58|4.215053763333334|           4.22|\n",
      "|  2|2019-06-24|     1548|50.83870968|          50.84|       4.23655914|           4.24|\n",
      "|  3|2019-08-24|     1487|48.83870968|          48.84|4.069892473333334|           4.07|\n",
      "+---+----------+---------+-----------+---------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#months between\n",
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"datesDiff\", datediff(current_date(),col(\"date\"))) \\\n",
    "  .withColumn(\"montsDiff\", months_between(current_date(),col(\"date\"))) \\\n",
    "  .withColumn(\"montsDiff_round\",round(months_between(current_date(),col(\"date\")),2)) \\\n",
    "  .withColumn(\"yearsDiff\",months_between(current_date(),col(\"date\"))/lit(12)) \\\n",
    "  .withColumn(\"yearsDiff_round\",round(months_between(current_date(),col(\"date\"))/lit(12),2)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d2843d9-89fe-4f8b-9e42-22b11383dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|years_diff|\n",
      "+----------+\n",
      "|     -4.22|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select round(months_between('2019-07-01',current_date())/12,2) as years_diff\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61023c1c-d4b5-4857-8991-970460bc1711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
