{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93869ac6-df0a-4e5e-8bf8-8219d132c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      "\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|id |zipcode|type    |city               |state|population|\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "|1  |704    |STANDARD|null               |PR   |30100     |\n",
      "|2  |704    |null    |PASEO COSTA DEL SUR|PR   |null      |\n",
      "|3  |709    |null    |BDA SAN LUIS       |PR   |3700      |\n",
      "|4  |76166  |UNIQUE  |CINGULAR WIRELESS  |TX   |84000     |\n",
      "|5  |76177  |STANDARD|null               |TX   |null      |\n",
      "+---+-------+--------+-------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.master(\"local[1]\").appName(\"Examples\").getOrCreate()\n",
    "\n",
    "df = spark.read.options(header='true', inferSchema='true').csv(\"small_zipcode.csv\")\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f244e94-4e78-4f7e-88a3-672b94c155ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"state\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .csv(\"zipcodes-state1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae64512-b872-43c4-accf-6e9d8d22800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"state\",\"city\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .csv(\"zipcodes-state2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d235b52-21bd-452d-97b6-4bb23316b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(2) \\\n",
    "        .write.option(\"header\",True) \\\n",
    "        .partitionBy(\"state\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .csv(\"zipcodes-state-more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a1a36ab-43be-4972-b278-aff6f3391983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data skew\n",
    "df.write.option(\"header\",True) \\\n",
    "        .option(\"maxRecordsPerFile\", 2) \\\n",
    "        .partitionBy(\"state\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .csv(\"zipcodes-state3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b631b85f-23ec-4619-b86c-f22b859930c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      "\n",
      "+---+-------+--------+-------------------+----------+\n",
      "| id|zipcode|    type|               city|population|\n",
      "+---+-------+--------+-------------------+----------+\n",
      "|  1|    704|STANDARD|               null|     30100|\n",
      "|  2|    704|    null|PASEO COSTA DEL SUR|      null|\n",
      "|  3|    709|    null|       BDA SAN LUIS|      3700|\n",
      "+---+-------+--------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read specific partition\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.master(\"local[1]\").appName(\"Examples\").getOrCreate()\n",
    "df1=spark.read.option(\"header\",True).csv(\"zipcodes-state3/state=PR\")\n",
    "df1.printSchema()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98016a2c-b7ac-436e-a697-b10188db8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+------------+----------+-----+\n",
      "| id|zipcode|type|        city|population|state|\n",
      "+---+-------+----+------------+----------+-----+\n",
      "|  3|    709|null|BDA SAN LUIS|      3700|   PR|\n",
      "+---+-------+----+------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parqDF = spark.read.option(\"header\",True).csv(\"zipcodes-state3\")\n",
    "parqDF.createOrReplaceTempView(\"ZIPCODE\")\n",
    "spark.sql(\"select * from ZIPCODE  where state='PR' and city = 'BDA SAN LUIS'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0cb29-0e82-49ab-be18-b3ad46ecbd32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
